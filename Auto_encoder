import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
 
 
train_path = "wqtrainset.csv"  
test_path  = "collection5.csv"    
 
 
train_calls = pd.read_csv(train_path, header=None)
test_calls  = pd.read_csv(test_path,  header=None)
 
 
le = LabelEncoder()
 
train_labels = le.fit_transform(train_calls)
test_labels  = le.transform(test_calls)
 
 
 
SEQ_LEN = 256  
 
 
def chunk_sequence(labels, seq_len):
   
    total_labels = len(labels)
    remainder = total_labels % seq_len
    if remainder != 0:
        labels = labels[: total_labels - remainder]
    sequences = np.array(labels).reshape(-1, seq_len)
    return sequences
 
 
train_sequences = chunk_sequence(train_labels, SEQ_LEN)
test_sequences  = chunk_sequence(test_labels, SEQ_LEN)
 
print(f"Total training calls: {len(train_calls)} -> Training sequences: {train_sequences.shape[0]} of length {SEQ_LEN}")
print(f"Total test calls: {len(test_calls)} -> Test sequences: {test_sequences.shape[0]} of length {SEQ_LEN}")
 
 
 
train_tensor = torch.tensor(train_sequences, dtype=torch.long)
test_tensor  = torch.tensor(test_sequences, dtype=torch.long)
 
 
batch_size = 64
train_dataset = TensorDataset(train_tensor)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
 
 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)
 
class LSTMAutoencoder(nn.Module):
    def __init__(self, num_classes, embed_dim=16, hidden_dim=64):
        super(LSTMAutoencoder, self).__init__()
        self.embedding = nn.Embedding(num_classes, embed_dim)
        self.encoder_lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.decoder_lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)
        self.output_layer = nn.Linear(hidden_dim, 1)
    def forward(self, x):
        batch_size, seq_len = x.size()
        x_embed = self.embedding(x)                      
        _, (h_n, c_n) = self.encoder_lstm(x_embed)      
        decoder_inputs = torch.zeros(batch_size, seq_len, self.decoder_lstm.input_size, device=x.device)
        decoder_out, _ = self.decoder_lstm(decoder_inputs, (h_n, c_n))  
        out = self.output_layer(decoder_out)            
        out = out.squeeze(-1)                          
        return out
 
 
num_classes = len(le.classes_)  
model = LSTMAutoencoder(num_classes, embed_dim=16, hidden_dim=64).to(device)
 
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
 
 
epochs = 10
for epoch in range(1, epochs+1):
    model.train()
    total_loss = 0.0
    for batch_data in train_loader:
        batch_seq = batch_data[0].to(device)        
        optimizer.zero_grad()
        recon_seq = model(batch_seq)
        loss = criterion(recon_seq, batch_seq.float())
        loss.backward()
        optimizer.step()
        total_loss += loss.item() * batch_seq.size(0)
    avg_loss = total_loss / len(train_dataset)  
    print(f"Epoch {epoch}/{epochs}, Training Loss: {avg_loss:.6f}")
 
 
model.eval()
with torch.no_grad():
    train_recon = model(train_tensor.to(device))
    train_errors = ((train_recon - train_tensor.to(device).float()) ** 2).mean(dim=1).cpu().numpy()
    threshold = train_errors.mean() + 3 * train_errors.std()
    print(f"Computed anomaly threshold (mean + 3Ïƒ) = {threshold}")
 
 
    test_recon = model(test_tensor.to(device))
    test_errors = ((test_recon - test_tensor.to(device).float()) ** 2).mean(dim=1).cpu().numpy()
 
    anomaly_flags = test_errors > threshold
    num_anomalies = np.sum(anomaly_flags)
    print(f"Number of anomaly sequences in test: {num_anomalies} out of {len(test_errors)}")
 
    for idx, is_anomaly in enumerate(anomaly_flags):
        if is_anomaly:
            print(f"Sequence {idx} flagged as anomaly with loss {test_errors[idx]:.6f}")
 
 
    results_df = pd.DataFrame({
        "sequence_index": np.arange(len(test_errors)),
        "loss": test_errors,
        "anomaly_flag": anomaly_flags.astype(int)
    })
    results_df.to_csv("test_anomaly_results.csv", index=False)
    print("Anomaly detection results saved to test_anomaly_results.csv")
 
